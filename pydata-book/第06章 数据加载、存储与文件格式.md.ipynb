{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第06章 数据加载、存储与文件格式.md\n",
    "\n",
    "访问数据是使用本书所介绍的这些工具的第一步。我会着重介绍pandas的数据输入与输出，虽然别的库中也有不少以此为目的的工具。\n",
    "\n",
    "输入输出通常可以划分为几个大类：\n",
    "    读取文本文件和其他更高效的磁盘存储格式，\n",
    "    加载数据库中的数据，\n",
    "    利用Web API操作网络资源。\n",
    "    \n",
    "6.1 读写文本格式的数据\n",
    "pandas提供了一些用于将表格型数据读取为DataFrame对象的函数。表6-1对它们进行了总结，其中read_csv和read_table可能会是你今后用得最多的。\n",
    "我将大致介绍一下这些函数在将文本数据转换为DataFrame时所用到的一些技术。这些函数的选项可以划分为以下几个大类：\n",
    "\n",
    "索引：将一个或多个列当做返回的DataFrame处理，以及是否从文件、用户获取列名。\n",
    "类型推断和数据转换：包括用户定义值的转换、和自定义的缺失值标记列表等。\n",
    "日期解析：包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列。\n",
    "迭代：支持对大文件进行逐块迭代。\n",
    "不规整数据问题：跳过一些行、页脚、注释或其他一些不重要的东西（比如由成千上万个逗号隔开的数值数据）。\n",
    "由于该文件以逗号分隔，所以我们可以使用read_csv将其读入一个DataFrame：\n",
    "\n",
    "df = pd.read_csv('examples/ex1.csv')\n",
    "我们还可以使用read_table，并指定分隔符：\n",
    "\n",
    "In [11]: pd.read_table('examples/ex1.csv', sep=',')\n",
    "读入该文件的办法有两个。你可以让pandas为其分配默认的列名，也可以自己定义列名：\n",
    "\n",
    "In [13]: pd.read_csv('examples/ex2.csv', header=None)\n",
    "In [14]: pd.read_csv('examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])\n",
    "假设你希望将message列做成DataFrame的索引。你可以明确表示要将该列放到索引4的位置上，也可以通过index_col参数指定\"message\"：\n",
    "\n",
    "In [15]: names = ['a', 'b', 'c', 'd', 'message']\n",
    "\n",
    "In [16]: pd.read_csv('examples/ex2.csv', names=names, index_col='message')\n",
    "\n",
    "如果希望将多个列做成一个层次化索引，只需传入由列编号或列名组成的列表即可：\n",
    "\n",
    "In [17]: !cat examples/csv_mindex.csv\n",
    "key1,key2,value1,value2\n",
    "one,a,1,2\n",
    "one,b,3,4\n",
    "one,c,5,6\n",
    "one,d,7,8\n",
    "two,a,9,10\n",
    "two,b,11,12\n",
    "two,c,13,14\n",
    "two,d,15,16\n",
    "\n",
    "In [18]: parsed = pd.read_csv('examples/csv_mindex.csv',\n",
    "   ....:                      index_col=['key1', 'key2'])\n",
    "\n",
    "In [19]: parsed\n",
    "\n",
    "有些情况下，有些表格可能不是用固定的分隔符去分隔字段的（比如空白符或其它模式）。看看下面这个文本文件：\n",
    "\n",
    "In [20]: list(open('examples/ex3.txt'))\n",
    "\n",
    "虽然可以手动对数据进行规整，这里的字段是被数量不同的空白字符间隔开的。这种情况下，你可以传递一个正则表达式作为read_table的分隔符。可以用正则表达式表达为\\s+，于是有：\n",
    "\n",
    "In [21]: result = pd.read_table('examples/ex3.txt', sep='\\s+')\n",
    "\n",
    "这里，由于列名比数据行的数量少，所以read_table推断第一列应该是DataFrame的索引。\n",
    "\n",
    "这些解析器函数还有许多参数可以帮助你处理各种各样的异形文件格式（表6-2列出了一些）。比如说，你可以用skiprows跳过文件的第一行、第三行和第四行：\n",
    "\n",
    "In [23]: !cat examples/ex4.csv\n",
    "# hey!\n",
    "a,b,c,d,message\n",
    "# just wanted to make things more difficult for you\n",
    "# who reads CSV files with computers, anyway?\n",
    "1,2,3,4,hello\n",
    "5,6,7,8,world\n",
    "9,10,11,12,foo\n",
    "In [24]: pd.read_csv('examples/ex4.csv', skiprows=[0, 2, 3])\n",
    "Out[24]: \n",
    "   a   b   c   d message\n",
    "0  1   2   3   4   hello\n",
    "1  5   6   7   8   world\n",
    "2  9  10  11  12     foo\n",
    "\n",
    "缺失值处理是文件解析任务中的一个重要组成部分。缺失数据经常是要么没有（空字符串），要么用某个标记值表示。默认情况下，pandas会用一组经常出现的标记值进行识别，比如NA及NULL：\n",
    "\n",
    "逐块读取文本文件\n",
    "在处理很大的文件时，或找出大文件中的参数集以便于后续处理时，你可能只想读取文件的一小部分或逐块对文件进行迭代。\n",
    "\n",
    "在看大文件之前，我们先设置pandas显示地更紧些：\n",
    "\n",
    "In [33]: pd.options.display.max_rows = 10\n",
    "\n",
    "如果只想读取几行（避免读取整个文件），通过nrows进行指定即可：\n",
    "\n",
    "In [36]: pd.read_csv('examples/ex6.csv', nrows=5)\n",
    "\n",
    "将数据写出到文本格式\n",
    "数据也可以被输出为分隔符格式的文本。我们再来看看之前读过的一个CSV文件：\n",
    "\n",
    "In [41]: data = pd.read_csv('examples/ex5.csv')\n",
    "\n",
    "In [42]: data\n",
    "\n",
    "利用DataFrame的to_csv方法，我们可以将数据写到一个以逗号分隔的文件中：\n",
    "\n",
    "In [43]: data.to_csv('examples/out.csv')\n",
    "\n",
    "当然，还可以使用其他分隔符（由于这里直接写出到sys.stdout，所以仅仅是打印出文本结果而已）：\n",
    "\n",
    "In [45]: import sys\n",
    "\n",
    "In [46]: data.to_csv(sys.stdout, sep='|')\n",
    "\n",
    "缺失值在输出结果中会被表示为空字符串。你可能希望将其表示为别的标记值：\n",
    "\n",
    "In [47]: data.to_csv(sys.stdout, na_rep='NULL')\n",
    "\n",
    "如果没有设置其他选项，则会写出行和列的标签。当然，它们也都可以被禁用：\n",
    "\n",
    "In [48]: data.to_csv(sys.stdout, index=False, header=False)\n",
    "\n",
    "此外，你还可以只写出一部分的列，并以你指定的顺序排列：\n",
    "\n",
    "In [49]: data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c'])\n",
    "\n",
    "Series也有一个to_csv方法：\n",
    "\n",
    "In [50]: dates = pd.date_range('1/1/2000', periods=7)\n",
    "\n",
    "In [51]: ts = pd.Series(np.arange(7), index=dates)\n",
    "\n",
    "In [52]: ts.to_csv('examples/tseries.csv')\n",
    "\n",
    "In [53]: !cat examples/tseries.csv\n",
    "处理分隔符格式\n",
    "大部分存储在磁盘上的表格型数据都能用pandas.read_table进行加载。然而，有时还是需要做一些手工处理。由于接收到含有畸形行的文件而使read_table出毛病的情况并不少见。为了说明这些基本工具，看看下面这个简单的CSV文件：\n",
    "\n",
    "In [54]: !cat examples/ex7.csv\n",
    "\"a\",\"b\",\"c\"\n",
    "\"1\",\"2\",\"3\"\n",
    "\"1\",\"2\",\"3\"\n",
    "对于任何单字符分隔符文件，可以直接使用Python内置的csv模块。将任意已打开的文件或文件型的对象传给csv.reader：\n",
    "\n",
    "对这个reader进行迭代将会为每行产生一个元组（并移除了所有的引号）：对这个reader进行迭代将会为每行产生一个元组（并移除了所有的引号）：\n",
    "\n",
    "In [56]: for line in reader:\n",
    "   ....:     print(line)\n",
    "['a', 'b', 'c']\n",
    "['1', '2', '3']\n",
    "['1', '2', '3']\n",
    "\n",
    "现在，为了使数据格式合乎要求，你需要对其做一些整理工作。我们一步一步来做。首先，读取文件到一个多行的列表中：\n",
    "\n",
    "In [57]: with open('examples/ex7.csv') as f:\n",
    "   ....:     lines = list(csv.reader(f))\n",
    "然后，我们将这些行分为标题行和数据行：\n",
    "\n",
    "In [58]: header, values = lines[0], lines[1:]\n",
    "然后，我们可以用字典构造式和zip(*values)，后者将行转置为列，创建数据列的字典：\n",
    "\n",
    "In [59]: data_dict = {h: v for h, v in zip(header, zip(*values))}\n",
    "\n",
    "In [60]: data_dict\n",
    "Out[60]: {'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}\n",
    "CSV文件的形式有很多。只需定义csv.Dialect的一个子类即可定义出新格式（如专门的分隔符、字符串引用约定、行结束符等）：\n",
    "\n",
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator = '\\n'\n",
    "    delimiter = ';'\n",
    "    quotechar = '\"'\n",
    "    quoting = csv.QUOTE_MINIMAL\n",
    "reader = csv.reader(f, dialect=my_dialect)\n",
    "各个CSV语支的参数也可以用关键字的形式提供给csv.reader，而无需定义子类：\n",
    "\n",
    "reader = csv.reader(f, delimiter='|')\n",
    "\n",
    "笔记：对于那些使用复杂分隔符或多字符分隔符的文件，csv模块就无能为力了。这种情况下，你就只能使用字符串的split方法或正则表达式方法re.split进行行拆分和其他整理工作了。\n",
    "\n",
    "要手工输出分隔符文件，你可以使用csv.writer。它接受一个已打开且可写的文件对象以及跟csv.reader相同的那些语支和格式化选项：\n",
    "\n",
    "with open('mydata.csv', 'w') as f:\n",
    "    writer = csv.writer(f, dialect=my_dialect)\n",
    "    writer.writerow(('one', 'two', 'three'))\n",
    "    writer.writerow(('1', '2', '3'))\n",
    "    writer.writerow(('4', '5', '6'))\n",
    "    writer.writerow(('7', '8', '9'))\n",
    "    \n",
    "JSON数据\n",
    "JSON（JavaScript Object Notation的简称）已经成为通过HTTP请求在Web浏览器和其他应用程序之间发送数据的标准格式之一。它是一种比表格型文本格式（如CSV）灵活得多的数据格式。下面是一个例子：\n",
    "\n",
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 38,\n",
    "               \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "除其空值null和一些其他的细微差别（如列表末尾不允许存在多余的逗号）之外，JSON非常接近于有效的Python代码。基本类型有对象（字典）、数组（列表）、字符串、数值、布尔值以及null。对象中所有的键都必须是字符串。许多Python库都可以读写JSON数据。我将使用json，因为它是构建于Python标准库中的。通过json.loads即可将JSON字符串转换成Python形式：\n",
    "\n",
    "In [62]: import json\n",
    "\n",
    "In [63]: result = json.loads(obj)\n",
    "\n",
    "In [64]: result\n",
    "Out[64]: \n",
    "{'name': 'Wes',\n",
    " 'pet': None,\n",
    " 'places_lived': ['United States', 'Spain', 'Germany'],\n",
    " 'siblings': [{'age': 30, 'name': 'Scott', 'pets': ['Zeus', 'Zuko']},\n",
    "  {'age': 38, 'name': 'Katie', 'pets': ['Sixes', 'Stache', 'Cisco']}]}\n",
    "  \n",
    "json.dumps则将Python对象转换成JSON格式：\n",
    "\n",
    "In [65]: asjson = json.dumps(result)\n",
    "如何将（一个或一组）JSON对象转换为DataFrame或其他便于分析的数据结构就由你决定了。最简单方便的方式是：向DataFrame构造器传入一个字典的列表（就是原先的JSON对象），并选取数据字段的子集：\n",
    "\n",
    "In [66]: siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])\n",
    "\n",
    "In [67]: siblings\n",
    "Out[67]: \n",
    "    name  age\n",
    "0  Scott   30\n",
    "1  Katie   38\n",
    "\n",
    "XML和HTML：Web信息收集\n",
    "Python有许多可以读写常见的HTML和XML格式数据的库，包括lxml、Beautiful Soup和html5lib。lxml的速度比较快，但其它的库处理有误的HTML或XML文件更好。\n",
    "\n",
    "pandas有一个内置的功能，read_html，它可以使用lxml和Beautiful Soup自动将HTML文件中的表格解析为DataFrame对象。为了进行展示，我从美国联邦存款保险公司下载了一个HTML文件（pandas文档中也使用过），它记录了银行倒闭的情况。首先，你需要安装read_html用到的库：\n",
    "\n",
    "利用lxml.objectify解析XML\n",
    "XML（Extensible Markup Language）是另一种常见的支持分层、嵌套数据以及元数据的结构化数据格式。本书所使用的这些文件实际上来自于一个很大的XML文档。\n",
    "\n",
    "前面，我介绍了pandas.read_html函数，它可以使用lxml或Beautiful Soup从HTML解析数据。XML和HTML的结构很相似，但XML更为通用。这里，我会用一个例子演示如何利用lxml从XML格式解析数据。\n",
    "\n",
    "6.2 二进制数据格式\n",
    "实现数据的高效二进制格式存储最简单的办法之一是使用Python内置的pickle序列化。pandas对象都有一个用于将数据以pickle格式保存到磁盘上的to_pickle方法：\n",
    "注意：pickle仅建议用于短期存储格式。其原因是很难保证该格式永远是稳定的；今天pickle的对象可能无法被后续版本的库unpickle出来。虽然我尽力保证这种事情不会发生在pandas中，但是今后的某个时候说不定还是得“打破”该pickle格式。\n",
    "\n",
    "pandas内置支持两个二进制数据格式：HDF5和MessagePack。下一节，我会给出几个HDF5的例子，但我建议你尝试下不同的文件格式，看看它们的速度以及是否适合你的分析工作。pandas或NumPy数据的其它存储格式有：\n",
    "\n",
    "bcolz：一种可压缩的列存储二进制格式，基于Blosc压缩库。\n",
    "Feather：我与R语言社区的Hadley Wickham设计的一种跨语言的列存储文件格式。Feather使用了Apache Arrow的列式内存格式。\n",
    "\n",
    "使用HDF5格式\n",
    "HDF5是一种存储大规模科学数组数据的非常好的文件格式。它可以被作为C标准库，带有许多语言的接口，如Java、Python和MATLAB等。HDF5中的HDF指的是层次型数据格式（hierarchical data format）。每个HDF5文件都含有一个文件系统式的节点结构，它使你能够存储多个数据集并支持元数据。与其他简单格式相比，HDF5支持多种压缩器的即时压缩，还能更高效地存储重复模式数据。对于那些非常大的无法直接放入内存的数据集，HDF5就是不错的选择，因为它可以高效地分块读写。\n",
    "\n",
    "虽然可以用PyTables或h5py库直接访问HDF5文件，pandas提供了更为高级的接口，可以简化存储Series和DataFrame对象。HDFStore类可以像字典一样，处理低级的细节：\n",
    "\n",
    "如果需要本地处理海量数据，我建议你好好研究一下PyTables和h5py，看看它们能满足你的哪些需求。。由于许多数据分析问题都是IO密集型（而不是CPU密集型），利用HDF5这样的工具能显著提升应用程序的效率。\n",
    "\n",
    "注意：HDF5不是数据库。它最适合用作“一次写多次读”的数据集。虽然数据可以在任何时候被添加到文件中，但如果同时发生多个写操作，文件就可能会被破坏。\n",
    "\n",
    "读取Microsoft Excel文件\n",
    "pandas的ExcelFile类或pandas.read_excel函数支持读取存储在Excel 2003（或更高版本）中的表格型数据。这两个工具分别使用扩展包xlrd和openpyxl读取XLS和XLSX文件。你可以用pip或conda安装它们。\n",
    "\n",
    "要使用ExcelFile，通过传递xls或xlsx路径创建一个实例：\n",
    "\n",
    "In [104]: xlsx = pd.ExcelFile('examples/ex1.xlsx')\n",
    "存储在表单中的数据可以read_excel读取到DataFrame（原书这里写的是用parse解析，但代码中用的是read_excel，是个笔误：只换了代码，没有改文字）：\n",
    "\n",
    "In [105]: pd.read_excel(xlsx, 'Sheet1')\n",
    "Out[105]: \n",
    "   a   b   c   d message\n",
    "0  1   2   3   4   hello\n",
    "1  5   6   7   8   world\n",
    "2  9  10  11  12     foo\n",
    "\n",
    "如果要读取一个文件中的多个表单，创建ExcelFile会更快，但你也可以将文件名传递到pandas.read_excel：\n",
    "\n",
    "In [106]: frame = pd.read_excel('examples/ex1.xlsx', 'Sheet1')\n",
    "\n",
    "In [107]: frame\n",
    "Out[107]: \n",
    "   a   b   c   d message\n",
    "0  1   2   3   4   hello\n",
    "1  5   6   7   8   world\n",
    "2  9  10  11  12     foo\n",
    "如果要将pandas数据写入为Excel格式，你必须首先创建一个ExcelWriter，然后使用pandas对象的to_excel方法将数据写入到其中：\n",
    "\n",
    "In [108]: writer = pd.ExcelWriter('examples/ex2.xlsx')\n",
    "\n",
    "In [109]: frame.to_excel(writer, 'Sheet1')\n",
    "\n",
    "In [110]: writer.save()\n",
    "你还可以不使用ExcelWriter，而是传递文件的路径到to_excel：\n",
    "\n",
    "In [111]: frame.to_excel('examples/ex2.xlsx')\n",
    "6.3 Web APIs交互\n",
    "许多网站都有一些通过JSON或其他格式提供数据的公共API。通过Python访问这些API的办法有不少。一个简单易用的办法（推荐）是requests包（http://docs.python-requests.org）。\n",
    "\n",
    "为了搜索最新的30个GitHub上的pandas主题，我们可以发一个HTTP GET请求，使用requests扩展库：\n",
    "\n",
    "In [113]: import requests\n",
    "\n",
    "In [114]: url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "\n",
    "In [115]: resp = requests.get(url)\n",
    "\n",
    "In [116]: resp\n",
    "Out[116]: <Response [200]>\n",
    "响应对象的json方法会返回一个包含被解析过的JSON字典，加载到一个Python对象中：\n",
    "\n",
    "In [117]: data = resp.json()\n",
    "\n",
    "In [118]: data[0]['title']\n",
    "Out[118]: 'Period does not round down for frequencies less that 1 hour'\n",
    "data中的每个元素都是一个包含所有GitHub主题页数据（不包含评论）的字典。我们可以直接传递数据到DataFrame，并提取感兴趣的字段：\n",
    "\n",
    "6.4 数据库交互\n",
    "在商业场景下，大多数数据可能不是存储在文本或Excel文件中。基于SQL的关系型数据库（如SQL Server、PostgreSQL和MySQL等）使用非常广泛，其它一些数据库也很流行。数据库的选择通常取决于性能、数据完整性以及应用程序的伸缩性需求。\n",
    "\n",
    "将数据从SQL加载到DataFrame的过程很简单，此外pandas还有一些能够简化该过程的函数。例如，我将使用SQLite数据库（通过Python内置的sqlite3驱动器）：\n",
    "\n",
    "6.5 总结\n",
    "访问数据通常是数据分析的第一步。在本章中，我们已经学了一些有用的工具。在接下来的章节中，我们将深入研究数据规整、数据可视化、时间序列分析和其它主题。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
